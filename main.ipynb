{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'bbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a7ee7a8ee167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\M2IV\\PIC PROJ\\BNP\\CODE\\training\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m       \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m       \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bbox\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[1;31m# indicates to the model which tokens should be attended to and which should not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bbox'"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMForTokenClassification\n",
    "import torch\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "#from data_loading.funsd import train_dataloader,eval_dataloader\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Datset Options\n",
    "    parser.add_argument(\"--data_root\", type=str, default='./datasets/data',\n",
    "                        help=\"path to Dataset\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default='funsd',\n",
    "                        choices=['funsd', 'sroie'], help='Name of dataset')\n",
    "\n",
    "    # Models Options\n",
    "    parser.add_argument(\"--model\", type=str, default='LayoutLM',\n",
    "                        choices=['LayoutLM', 'LayoutLM'], help='model name')\n",
    "\n",
    "    # Train Options\n",
    "    parser.add_argument(\"--test_only\", action='store_true', default=False)\n",
    "    parser.add_argument(\"--save_val_results\", action='store_true', default=False,\n",
    "                        help=\"save results to \\\"./results\\\"\")\n",
    "    parser.add_argument(\"--num_train_epochs\", type=int, default=5,\n",
    "                        help=\"epoch number (default: 5)\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5,\n",
    "                        help=\"learning rate (default: 0.00005)\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2,\n",
    "                        help='batch size (default: 2)')\n",
    "    parser.add_argument(\"--val_batch_size\", type=int, default=1,\n",
    "                        help='batch size for validation (default: 1)')\n",
    "    parser.add_argument(\"--ckpt\", default=None, type=str,\n",
    "                        help=\"restore from checkpoint\")\n",
    "    parser.add_argument(\"--gpu_id\", type=str, default='0',\n",
    "                        help=\"GPU ID\")\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=1,\n",
    "                        help=\"random seed (default: 1)\")\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opts = get_argparser().parse_args()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = opts.gpu_id\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device: %s\" % device)\n",
    "\n",
    "    # Setup random seed\n",
    "    torch.manual_seed(opts.random_seed)\n",
    "    np.random.seed(opts.random_seed)\n",
    "    random.seed(opts.random_seed)\n",
    "\n",
    "    # define number of labels refer to different dataset\n",
    "    if opts.dataset.lower() == 'funsd':\n",
    "        def get_labels(path):\n",
    "            with open(path, \"r\") as f:\n",
    "                labels = f.read().splitlines()\n",
    "            if \"O\" not in labels:\n",
    "                labels = [\"O\"] + labels\n",
    "            return labels\n",
    "        labels = get_labels(os.path.join(opts.data_root,\"labels.txt\"))\n",
    "        num_labels = len(labels)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # define model\n",
    "    if opts.model == 'LayoutLM':\n",
    "        model = LayoutLMForTokenClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=num_labels)\n",
    "    else:\n",
    "        pass\n",
    "    model.to(device)\n",
    "\n",
    "    # define optimization\n",
    "    optimizer = AdamW(model.parameters(), lr=opts.lr)\n",
    "    if opts.test_only:\n",
    "        evaluate(model=model, device=device, train_dataloader=train_dataloader, eval_dataloader=eval_dataloader)\n",
    "        return\n",
    "    else:\n",
    "        train(model=model, device=device, train_dataloader=train_dataloader, eval_dataloader=eval_dataloader,optimizer=optimizer)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
